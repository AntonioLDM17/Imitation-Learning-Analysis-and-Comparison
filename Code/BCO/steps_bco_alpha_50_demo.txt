    """ 
    python train_bco_nuevo.py --env halfcheetah --pre_interactions 2000 --alpha 0.5 --num_iterations 5 --policy_epochs 20 --iter_policy_epochs 36 --demo_episodes 50
    === STEPS SUMMARY ===
    N (demo transitions)       = 56,055
    I_pre                      = 2,000
    alpha                      = 0.5
    num_iterations (T)         = 5
    policy_epochs (E)          = 20
    iter_policy_epochs (R)     = 36
    → env_steps esperado       = 7,000
    → bc_steps esperado        = 11,211,000
    → total_global_steps ≈     = 11,218,000
    """
    """
    python train_bco_nuevo.py --env halfcheetah --pre_interactions 2000 --alpha 0.5 --num_iterations 2 --policy_epochs 20 --iter_policy_epochs 10 --demo_episodes 50
    === STEPS SUMMARY ===
    N (demo transitions)       = 56,055
    I_pre                      = 2,000
    alpha                      = 0.5
    num_iterations (T)         = 2
    policy_epochs (E)          = 20
    iter_policy_epochs (R)     = 10
    → env_steps esperado       = 4,000
    → bc_steps esperado        = 2,242,200
    → total_global_steps ≈     = 2,246,200
    """
    """ 
    python train_bco_nuevo.py --env halfcheetah --pre_interactions 20000 --alpha 0.5 --num_iterations 2 --policy_epochs 20 --iter_policy_epochs 5 --demo_episodes 50
    === STEPS SUMMARY ===
    N (demo transitions)       = 56,055
    I_pre                      = 20,000
    alpha                      = 0.5
    num_iterations (T)         = 2
    policy_epochs (E)          = 20
    iter_policy_epochs (R)     = 5
    → env_steps esperado       = 40,000
    → bc_steps esperado        = 1,681,650
    → total_global_steps ≈     = 1,721,650
    
    Training complete!
    Total environment steps: 40000
    Total BC steps: 1681650
    Expected total global steps: 1721650
    Actual total global steps: 1721650
    Final evaluation: mean reward = 3695.29, std = 1293.02
    """
    """ 
    python train_bco_nuevo.py --env halfcheetah --pre_interactions 160000 --alpha 0.5 --num_iterations 2 --policy_epochs 20 --iter_policy_epochs 5 --demo_episodes 50
    === STEPS SUMMARY ===
    N (demo transitions)       = 56,055
    I_pre                      = 160,000
    alpha                      = 0.5
    num_iterations (T)         = 2
    policy_epochs (E)          = 20
    iter_policy_epochs (R)     = 5
    → env_steps esperado       = 320,000
    → bc_steps esperado        = 1,681,650
    → total_global_steps ≈     = 2,001,650
    Training complete!
    Total environment steps: 320000
    Total BC steps: 1681650
    Expected total global steps: 2001650
    Actual total global steps: 2001650
    Final evaluation: mean reward = 4150.99, std = 2181.87
    """