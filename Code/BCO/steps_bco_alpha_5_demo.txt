    """ 
    python train_bco_nuevo.py --env halfcheetah --pre_interactions 120000 --alpha 0.5 --num_iterations 2 --policy_epochs 10 --iter_policy_epochs 50 --demo_episodes 5
    === STEPS SUMMARY ===
    N (demo transitions)       = 8,007
    I_pre                      = 120,000
    alpha                      = 0.5
    num_iterations (T)         = 2
    policy_epochs (E)          = 10
    iter_policy_epochs (R)     = 50
    → env_steps esperado       = 240,000
    → bc_steps esperado        = 880,770
    → total_global_steps ≈     = 1,120,770
    Training complete!
    Total environment steps: 240000
    Total BC steps: 880770
    Expected total global steps: 1120770
    Actual total global steps: 1120770
    Final evaluation: mean reward = 3206.71, std = 1659.68
    """
    """ 
    python train_bco_nuevo.py --env halfcheetah --pre_interactions 110000 --alpha 0.5 --num_iterations 2 --policy_epochs 5 --iter_policy_epochs 110 --demo_episodes 5 
    === STEPS SUMMARY ===
    N (demo transitions)       = 8,007
    I_pre                      = 110,000
    alpha                      = 0.5
    num_iterations (T)         = 2
    policy_epochs (E)          = 5
    iter_policy_epochs (R)     = 110
    → env_steps esperado       = 220,000
    → bc_steps esperado        = 1,801,575
    → total_global_steps ≈     = 2,021,575
    Training complete!
    Total environment steps: 220000
    Total BC steps: 1801575
    Expected total global steps: 2021575
    Actual total global steps: 2021575
    Final evaluation: mean reward = 3653.51, std = 2076.45
    """