env: halfcheetah
timesteps: 2000000
seed: 44
demo_episodes: 100
architecture:
  policy_network:
    type: MLP
    hidden_layers:
    - 64
    - 64
    activation: Tanh
    head: "Gaussian (μ, σ) with tanh squash"
  value_network:
    hidden_layers:
    - 64
    - 64
    activation: Tanh
    note: generated by SB3 MlpPolicy but not used in BC loss
training:
  method: Behavioral Cloning (supervised)
  library: imitation.algorithms.bc + SB3 MlpPolicy
  optimizer: Adam
  learning_rate: 0.001
  batch_size: 64
  epochs: implicit (timesteps / demo_steps)
  loss: Negative Log-Likelihood
  total_timesteps: 2000000
